# AUTOGENERATED FROM C#. DO NOT MODIFY.

from tdw.webgl.trials.tests.output_data import OutputData
from typing import Dict


class OutputDataBenchmark(OutputData):
    """
    This trial benchmarks the speed of writing and sending output data. There is no human user input.
    """

    def __init__(self, avatar_position: Dict[str, float] = None, avatar_look_at: Dict[str, float] = None, move_by: Dict[str, float] = None, rotate_by: float = 0.001, image_capture: bool = False, photodiode: bool = False, scene_name: str = "box_room_2018", model_name: str = "octahedron", scale: Dict[str, float] = None, grid_size: Dict[str, int] = None, force: Dict[str, float] = None, num_frames: int = 3600, frames_per_forces: int = 300):
        """
        :param avatar_position: The position of the avatar.
        :param avatar_look_at: The avatar will look at this position.
        :param move_by: The avatar will move by this delta per frame. This will make it harder for output data to compress.
        :param rotate_by: The avatar's camera will rotate around the yaw axis by this delta per frame. This will make it harder for output data to compress.
        :param image_capture: If true, capture image data per-frame. This is VERY expensive but it's required for the trial playback test.
        :param photodiode: If true, add a Photodiode add-on (add a UI square that changes from white to black per frame).
        :param scene_name: The name of the scene.
        :param model_name: The name of the test model.
        :param scale: The scale of the test model.
        :param grid_size: The size of the grid of objects. This determines how many objects there are and where they are. This vector will be multiplied by a factor to span the room.
        :param force: Apply this force to each object.
        :param num_frames: Run the simulation for this many frames.
        :param frames_per_forces: Re-apply forces after this many frames have elapsed.
        """

        super().__init__(scene_name=scene_name, model_name=model_name, scale=scale, grid_size=grid_size, force=force, num_frames=num_frames, frames_per_forces=frames_per_forces)
        if avatar_position is None:
            """:field
            The position of the avatar.
            """
            self.avatar_position: Dict[str, float] = {"x": 0, "y": 2.6, "z": -4}
        else:
            self.avatar_position = avatar_position
        if avatar_look_at is None:
            """:field
            The avatar will look at this position.
            """
            self.avatar_look_at: Dict[str, float] = {"x": 0, "y": 1.5, "z": 0}
        else:
            self.avatar_look_at = avatar_look_at
        if move_by is None:
            """:field
            The avatar will move by this delta per frame. This will make it harder for output data to compress.
            """
            self.move_by: Dict[str, float] = {"x": 0.001, "y": 0, "z": 0.001}
        else:
            self.move_by = move_by
        """:field
        The avatar's camera will rotate around the yaw axis by this delta per frame. This will make it harder for output data to compress.
        """
        self.rotate_by: float = rotate_by
        """:field
        If true, capture image data per-frame. This is VERY expensive but it's required for the trial playback test.
        """
        self.image_capture: bool = image_capture
        """:field
        If true, add a Photodiode add-on (add a UI square that changes from white to black per frame).
        """
        self.photodiode: bool = photodiode
